# Snowflake Data Science - Retail CLV Regression Demo

## ‚ö†Ô∏è Disclaimer

**All opinions, code, and implementation details in this repository are my own personal views and do not represent the views, policies, or recommendations of my employer or any organization I am affiliated with.**

This project is provided for educational and demonstration purposes only. It is not intended as professional advice or a recommendation for any specific use case. Use at your own risk.

A demonstration project for building a **Customer Lifetime Value (CLV) Regression Model** using Snowflake's ML capabilities, Feature Store, and Snowpark.

## üìã Prerequisites

- [Miniconda](https://docs.conda.io/en/latest/miniconda.html) or [Anaconda](https://www.anaconda.com/download) installed
- Snowflake account with ACCOUNTADMIN privileges (for initial setup)
- Git (optional, for cloning)

## üöÄ Quick Start

### 1. Create the Conda Environment

Run the setup script to create the conda environment:

```bash
# Make the script executable (first time only)
chmod +x setup_env.sh

# Run the setup script
./setup_env.sh
```

Or manually create the environment:

```bash
conda env create -f conda.yml
```

### 2. Activate the Environment

```bash
conda activate snowflake_ds
```

### 3. Configure Snowflake Connection

Create a `connection.json` file in the project root with your Snowflake credentials:

```json
{
    "account": "your_account_identifier",
    "user": "your_username",
    "password": "your_password",
    "warehouse": "your_warehouse",
    "role": "ACCOUNTADMIN"
}
```

> ‚ö†Ô∏è **Security Note**: The `connection.json` file is included in `.gitignore` to prevent accidental credential commits.

### 4. Run the Setup Notebook

Launch JupyterLab and run the setup notebook:

```bash
jupyter lab
```

Then open and run `Step01_Setup.ipynb` to:
- Create the demo role, warehouse, database, and schema
- Generate mock retail data (10,000 customers by default)
- Create the `CLV_TRAINING_DATA` view for ML training

## üìÅ Project Structure

```
Snowflake_Data_Science/
‚îú‚îÄ‚îÄ README.md                        # This file
‚îú‚îÄ‚îÄ IMPLEMENTATION_GUIDE.md          # Guide to choose implementation approach
‚îú‚îÄ‚îÄ conda.yml                        # Conda environment specification
‚îú‚îÄ‚îÄ setup_env.sh                     # Environment setup script
‚îú‚îÄ‚îÄ connection.json                  # Snowflake credentials (not in git)
‚îú‚îÄ‚îÄ helper/                          # Helper modules
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ useful_fns.py                # Helper functions (run_sql, etc.)
‚îú‚îÄ‚îÄ Step01_Setup.ipynb               # Database & data setup notebook
‚îî‚îÄ‚îÄ implementations/                 # Different implementation approaches
    ‚îú‚îÄ‚îÄ 01_snowflake_notebooks/      # ‚≠ê Beginner - Snowflake UI
    ‚îú‚îÄ‚îÄ 02_snowpark_sessions/        # ‚≠ê‚≠ê Intermediate - Local IDE
    ‚îî‚îÄ‚îÄ 03_ml_jobs/                  # ‚≠ê‚≠ê‚≠ê Advanced - Production
```

## üß≠ Choose Your Implementation Path

This repo intentionally mirrors the three maturity levels outlined in [`IMPLEMENTATION_GUIDE.md`](IMPLEMENTATION_GUIDE.md). Use the guide's decision tree plus the matrix below to pick the right entry point:

| Level | Approach | Best For | Complexity | Where It Runs |
|-------|----------|----------|------------|---------------|
| 1 ‚≠ê | Snowflake Notebooks | Learning, POCs, shareable demos | Low | Snowflake UI |
| 2 ‚≠ê‚≠ê | Snowpark Sessions | Local development, testing, CI | Medium | Local IDE + Snowflake warehouse |
| 3 ‚≠ê‚≠ê‚≠ê | ML Jobs | Production pipelines, scheduling | High | Snowflake serverless runtime |

### Quick Decision Reminders
- Need zero local setup? Start with `01_snowflake_notebooks/`.
- Want full IDE + Git workflow? Move into `02_snowpark_sessions/`.
- Ready for scheduled, scalable training + Model Registry? Deploy `03_ml_jobs/`.

The approaches are complementary‚Äîprototype in notebooks, industrialize via Snowpark, then operationalize with ML Jobs as shown below:

```
Snowflake Notebooks ‚îÄ‚îÄ‚ñ∫ Snowpark Sessions ‚îÄ‚îÄ‚ñ∫ ML Jobs
     Learn & share           Develop & test          Production-ready
         ‚≠ê                       ‚≠ê‚≠ê                       ‚≠ê‚≠ê‚≠ê
```

For screenshots, decision trees, and transition tips, keep [`IMPLEMENTATION_GUIDE.md`](IMPLEMENTATION_GUIDE.md) handy while you work through each folder.

## üìä Data Model

The demo creates two joinable tables for CLV prediction:

### CUSTOMER_DEMOGRAPHICS (4 features)
| Column | Type | Description |
|--------|------|-------------|
| CUSTOMER_ID | INTEGER | Primary key |
| AGE | INTEGER | Customer age (18-75) |
| ANNUAL_INCOME | DECIMAL | Estimated income ($20k-$200k) |
| LOYALTY_TIER | VARCHAR | Loyalty segment label (`low`, `medium`, `high`) |
| GENDER | VARCHAR | Customer gender label (`male`, `female`) |
| STATE | VARCHAR | Australian state/territory (NSW, VIC, QLD, WA, SA, TAS, NT, ACT) |
| TENURE_MONTHS | INTEGER | Months as customer (1-120) |

### PURCHASE_BEHAVIOR (3 features + target)
| Column | Type | Description |
|--------|------|-------------|
| CUSTOMER_ID | INTEGER | Foreign key |
| AVG_ORDER_VALUE | DECIMAL | Average transaction ($15-$500) |
| PURCHASE_FREQUENCY | DECIMAL | Orders per month (0.1-8) |
| RETURN_RATE | DECIMAL | % items returned (0-30%) |
| LIFETIME_VALUE | DECIMAL | **üéØ Regression target** |

### CLV_TRAINING_DATA (View)
A unified view joining both tables with derived features for ML training.

## üîß Configuration Options

Edit the configuration cell in `Step01_Setup.ipynb` to customize:

```python
admin_role = 'ACCOUNTADMIN'              # Admin role for setup
demo_role = 'RETAIL_REGRESSION_DEMO_ROLE' # Data scientist role
database_name = 'RETAIL_REGRESSION_DEMO'
schema_name = 'DS'
warehouse_name = 'RETAIL_REGRESSION_DEMO_WH'
warehouse_size = 'SMALL'
num_customers = 10000                     # Number of customers to generate
```

## üßπ Cleanup

To remove all created Snowflake objects, uncomment and run the cleanup cell at the end of `Step01_Setup.ipynb`.

To remove the conda environment:

```bash
conda deactivate
conda env remove -n snowflake_ds
```

## üì¶ Environment Packages

Key packages included in the conda environment:

| Package | Version | Purpose |
|---------|---------|---------|
| python | 3.10 | Runtime |
| snowflake-snowpark-python | 1.38.0 | Snowpark DataFrame API |
| snowflake-ml-python | 1.19.0 | ML functions & Feature Store |
| scikit-learn | 1.5.1 | ML algorithms |
| pandas | 2.3.1 | Data manipulation |
| jupyterlab | 4.4.4 | Notebook interface |
| matplotlib | 3.10.6 | Visualization |

## üìù License

This project is for demonstration purposes.

## üìö Additional Resources

- [Snowflake Notebooks Documentation](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks)
- [Snowpark Python Developer Guide](https://docs.snowflake.com/en/developer-guide/snowpark/python/index)
- [Snowflake ML Jobs](https://docs.snowflake.com/en/developer-guide/snowpark-ml/jobs)
- [Snowflake Model Registry](https://docs.snowflake.com/en/developer-guide/snowpark-ml/model-registry/overview)

